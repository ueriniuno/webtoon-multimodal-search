{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLLB"
      ],
      "metadata": {
        "id": "x2UT19DrecHZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN_qoKn5b6gw"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers torch accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "def load_nllb_pipeline(model_id=\"facebook/nllb-200-distilled-600M\"):\n",
        "    # GPU 가용 여부 확인\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "    print(f\"Loading model: {model_id} on {'GPU' if device == 0 else 'CPU'}...\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
        "\n",
        "    # 번역 파이프라인 구축\n",
        "    # eng_Latn: 영어(라틴어 기반), kor_Hang: 한국어(한글 기반)\n",
        "    translation_pipe = pipeline(\n",
        "        \"translation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        src_lang=\"eng_Latn\",\n",
        "        tgt_lang=\"kor_Hang\",\n",
        "        device=device\n",
        "    )\n",
        "    return translation_pipe\n",
        "\n",
        "# 1. 모델 로드\n",
        "nllb_translator = load_nllb_pipeline()\n",
        "\n",
        "# 2. 테스트용 영문 캡션 리스트 (VLM 결과물 예시)\n",
        "eng_captions = [\n",
        "    \"A funny looking white dog running across a sunlit park.\",\n",
        "    \"A close-up shot of a delicious pepperoni pizza with melting cheese.\",\n",
        "    \"A futuristic city skyline at night with neon lights and flying cars.\"\n",
        "]\n",
        "\n",
        "# 3. 번역 실행\n",
        "print(\"\\n--- 번역 결과 ---\")\n",
        "for caption in eng_captions:\n",
        "    # max_length는 캡션 길이에 따라 조절 가능\n",
        "    result = nllb_translator(caption, max_length=128)\n",
        "    ko_text = result[0]['translation_text']\n",
        "    print(f\"EN: {caption}\")\n",
        "    print(f\"KO: {ko_text}\\n\")"
      ],
      "metadata": {
        "id": "Sh0Vi9kZc1hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_captions = [\n",
        "    \"A cute white dog running across a sunlit park.\",\n",
        "    \"A close-up shot of a delicious pepperoni pizza with melting cheese.\",\n",
        "    \"A futuristic city skyline at night with neon lights and flying cars.\"\n",
        "]\n",
        "\n",
        "# 3. 번역 실행\n",
        "print(\"\\n--- 번역 결과 ---\")\n",
        "for caption in eng_captions:\n",
        "    # max_length는 캡션 길이에 따라 조절 가능\n",
        "    result = nllb_translator(caption, max_length=128)\n",
        "    ko_text = result[0]['translation_text']\n",
        "    print(f\"EN: {caption}\")\n",
        "    print(f\"KO: {ko_text}\\n\")"
      ],
      "metadata": {
        "id": "4b9sPN3IdVnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D98O942GdV_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXAONE"
      ],
      "metadata": {
        "id": "w9uYKOSmdqYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dr"
      ],
      "metadata": {
        "id": "VzAqXZiEh-Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d65c936a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "qcq0E-V1dtL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
        "\n",
        "# 1. 모델 및 토크나이저 설정\n",
        "model_id = \"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\"\n",
        "\n",
        "# 4비트 양자화 설정 (코랩 T4 GPU 메모리 확보용)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "print(\"EXAONE 3.5 모델을 로드 중입니다... (시간이 다소 소요될 수 있습니다)\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# 2. 번역 함수 정의\n",
        "def translate_to_korean(eng_text):\n",
        "    # EXAONE 전용 프롬프트 스타일 (임베딩에 적합하게 명사 위주/간결한 번역 요청)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"너는 유능한 번역가야. 입력되는 영어 텍스트를 임베딩 작업에 적합하도록 군더더기 없이 자연스러운 한국어로 번역해줘.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"다음 문장을 한국어로 번역해: {eng_text}\"}\n",
        "    ]\n",
        "\n",
        "    # 템플릿 적용\n",
        "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # 추론\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=128,\n",
        "            do_sample=False, # 결과의 일관성을 위해 False\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # 결과 텍스트만 추출\n",
        "    result = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "    return result.strip()\n",
        "\n",
        "# 3. 테스트 실행\n",
        "eng_caption = \"A golden retriever playing with a red ball on a green grass field.\"\n",
        "ko_translation = translate_to_korean(eng_caption)\n",
        "\n",
        "print(f\"\\n[VLM 결과]: {eng_caption}\")\n",
        "print(f\"[EXAONE 번역]: {ko_translation}\")"
      ],
      "metadata": {
        "id": "MEtaHFgNdugv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 테스트 실행\n",
        "eng_caption = \"A golden retriever playing with a red ball on a green grass field.\"\n",
        "ko_translation = translate_to_korean(eng_caption)\n",
        "\n",
        "print(f\"\\n[VLM 결과]: {eng_caption}\")\n",
        "print(f\"[EXAONE 번역]: {ko_translation}\")"
      ],
      "metadata": {
        "id": "fq6bUdgzeIua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "from tqdm import tqdm # 진행률 표시용\n",
        "\n",
        "# 1. 경로 설정\n",
        "input_folder = \"/content/drive/MyDrive/BOAZ_/split_jsons\"\n",
        "# 원본 보호를 위해 결과 전용 폴더를 만드는 것을 추천합니다.\n",
        "output_folder = \"/content/drive/MyDrive/BOAZ_/split_jsons_translated\"\n",
        "\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# 2. EXAONE 번역 함수 (캡션 특화 최적화)\n",
        "def translate_caption(eng_text):\n",
        "    # 캡션은 키워드가 나열된 경우가 많으므로, 문맥을 살리되 간결하게 번역하도록 프롬프트 구성\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"너는 웹툰 캡션 전문 번역가야. 입력되는 영어 묘사들을 자연스럽고 핵심 위주의 한국어로 번역해줘. 설명 없이 번역 결과만 출력해.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"번역해: {eng_text}\"}\n",
        "    ]\n",
        "\n",
        "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=512, # 캡션이 길 수 있으므로 충분히 설정\n",
        "            do_sample=False,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    result = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "    return result.strip()\n",
        "\n",
        "# 3. 폴더 내 파일 리스트 가져오기\n",
        "json_files = glob.glob(os.path.join(input_folder, \"*.json\"))\n",
        "print(f\"총 {len(json_files)}개의 파일을 찾았습니다.\")\n",
        "\n",
        "# 4. 루프를 돌며 번역 실행\n",
        "for file_path in tqdm(json_files, desc=\"번역 진행 중\"):\n",
        "    try:\n",
        "        # 파일 읽기\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # 'caption' 키가 있는지 확인 후 번역\n",
        "        if \"caption\" in data:\n",
        "            english_caption = data[\"caption\"]\n",
        "            korean_caption = translate_caption(english_caption)\n",
        "\n",
        "            # 데이터 업데이트\n",
        "            data[\"caption\"] = korean_caption\n",
        "\n",
        "            # 새 파일명 및 저장 (파일명은 그대로 유지)\n",
        "            file_name = os.path.basename(file_path)\n",
        "            save_path = os.path.join(output_folder, file_name)\n",
        "\n",
        "            with open(save_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "        else:\n",
        "            print(f\"\\n[Skip] 'caption' 키가 없습니다: {file_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n[Error] {file_path} 처리 중 오류 발생: {e}\")\n",
        "\n",
        "print(f\"\\n모든 작업이 완료되었습니다! 결과는 '{output_folder}'에서 확인하세요.\")"
      ],
      "metadata": {
        "id": "Vc0kdQl0iszv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WWIPW7Klit5a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}