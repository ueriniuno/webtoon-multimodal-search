# src/pipeline.py
import json
import os
from rank_bm25 import BM25Okapi
from qdrant_client.http import models

from src.config import settings
from src.schemas import SearchResult, ScenePayload
from src.router import LLMRouter
from src.expander import QueryExpander
from src.reranker import Reranker
# ğŸ‘‡ [ìˆ˜ì •] ë¶„ë¦¬ëœ í”„ë¡¬í”„íŠ¸ 4ì¢… ê°€ì ¸ì˜¤ê¸°
from src.prompts import RAG_GENERATION_CHAPTER, RAG_GENERATION_SCENE, RAG_SYSTEM_CHAPTER, RAG_SYSTEM_SCENE
from src.utils import load_json, KoreanTokenizer

class RAGPipeline:
    def __init__(self, db, embedding, llm):
        self.db = db
        self.embedding = embedding
        self.llm = llm
        
        print("ğŸ”§ [Pipeline] ì»´í¬ë„ŒíŠ¸ ë¡œë”©...")
        
        self.lookup = load_json(settings.paths["lookup_store"])
        if not self.lookup:
            print("âš ï¸ [Warning] Lookup Store ë¹„ì–´ìˆìŒ.")
        
        # ğŸ‘‡ [ìˆ˜ì •] characters.json íŒŒì¼ í†µì§¸ë¡œ ì½ì–´ì˜¤ê¸° (ëª¨ë“  ëª¨ë“œì—ì„œ ì „ì²´ ì •ë³´ ì‚¬ìš©)
        char_path = os.path.join(settings.paths["data_dir"], "characters.json")
        self.raw_character_info = ""
        if os.path.exists(char_path):
            with open(char_path, 'r', encoding='utf-8') as f:
                self.raw_character_info = f.read()
        else:
            print("âš ï¸ [Warning] characters.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        # í† í¬ë‚˜ì´ì € ì´ˆê¸°í™” (Kiwi)
        self.tokenizer = KoreanTokenizer()

        # BM25 ì—”ì§„ ë° ì±•í„°-ì´ë²¤íŠ¸ ë§¤í•‘ í…Œì´ë¸” ì´ˆê¸°í™”
        self.bm25 = None
        self.bm25_data = [] 
        self.chapter_event_map = {} # cid -> eid ë§¤í•‘ìš©
        self._init_bm25()
        
        self.router = LLMRouter(llm)
        self.expander = QueryExpander(llm)
        self.reranker = Reranker()

    def _init_bm25(self):
        bm25_path = os.path.join(settings.paths["data_dir"], "bm25_corpus.json")
        if not os.path.exists(bm25_path):
            print("âš ï¸ [Warning] BM25 ì½”í¼ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        print("   ğŸ“˜ BM25 ì¸ë±ìŠ¤ ìƒì„± ì¤‘ (í˜•íƒœì†Œ ë¶„ì„ ì ìš©)...")
        with open(bm25_path, 'r', encoding='utf-8') as f:
            self.bm25_data = json.load(f)
        
        # ğŸ‘‡ [ì¶”ê°€] ì±•í„°ê°€ ì†í•œ ì´ë²¤íŠ¸ë¥¼ ì°¾ê¸° ìœ„í•œ ë§¤í•‘ ìƒì„±
        for doc in self.bm25_data:
            p = doc['payload']
            cid = p.get('chapter_id')
            eid = p.get('event_id')
            if cid is not None and eid is not None:
                self.chapter_event_map[cid] = eid

        # í˜•íƒœì†Œ ë¶„ì„ ê¸°ë°˜ í† í°í™”
        tokenized_corpus = [self.tokenizer.tokenize(doc['text']) for doc in self.bm25_data]
        
        self.bm25 = BM25Okapi(tokenized_corpus)
        print("   âœ… BM25 ì¤€ë¹„ ì™„ë£Œ.")

    def hybrid_search(self, query, expanded_query, top_k=50):
        """
        [Vector Search] -> Expanded Query ì‚¬ìš© (ì˜ë¯¸ íŒŒì•…)
        [BM25 Search] -> Original + Expanded í˜¼í•© ì‚¬ìš© (ì•ˆì „ì„± + í™•ì¥ì„±)
        """
        # 1. Vector Search
        query_vector = self.embedding.get_embeddings(expanded_query).tolist()
        vector_hits = self.db.search(query_vector=query_vector, limit=top_k)
        
        # 2. BM25 Search
        bm25_hits = []
        if self.bm25:
            combined_query = f"{query} {expanded_query}" 
            tokenized_query = self.tokenizer.tokenize(combined_query)
            
            doc_scores = self.bm25.get_scores(tokenized_query)
            top_indexes = sorted(range(len(doc_scores)), key=lambda i: doc_scores[i], reverse=True)[:top_k]
            
            for idx in top_indexes:
                hit_data = self.bm25_data[idx]
                bm25_hits.append(models.ScoredPoint(
                    id=hit_data['id'],
                    version=0,
                    score=doc_scores[idx],
                    payload=hit_data['payload'],
                    vector=None
                ))

        # 3. RRF (Reciprocal Rank Fusion)
        k = 60
        fused_scores = {}
        
        for rank, hit in enumerate(vector_hits):
            if hit.id not in fused_scores:
                fused_scores[hit.id] = {"score": 0, "payload": hit.payload, "obj": hit}
            fused_scores[hit.id]["score"] += 1 / (k + rank + 1)
            
        for rank, hit in enumerate(bm25_hits):
            if hit.id not in fused_scores:
                fused_scores[hit.id] = {"score": 0, "payload": hit.payload, "obj": hit}
            fused_scores[hit.id]["score"] += 1 / (k + rank + 1)
            
        sorted_ids = sorted(fused_scores.keys(), key=lambda x: fused_scores[x]["score"], reverse=True)
        
        final_results = []
        for pid in sorted_ids[:top_k]:
            item = fused_scores[pid]
            original_pt = item['obj']
            final_results.append(models.ScoredPoint(
                id=original_pt.id,
                version=0,
                score=item['score'],
                payload=item['payload'],
                vector=None
            ))
            
        return final_results

    def _fetch_window_context(self, points, window_size=0):
        if window_size <= 0:
            return {p.id: p.payload['text'] for p in points}

        ids_to_fetch = set()
        for p in points:
            center_id = p.id
            ids_to_fetch.add(center_id)
            for i in range(1, window_size + 1):
                ids_to_fetch.add(center_id - i)
                ids_to_fetch.add(center_id + i)

        fetched_points = self.db.client.retrieve(
            collection_name=settings.rag["collection_name"],
            ids=list(ids_to_fetch)
        )
        text_map = {fp.id: fp.payload['text'] for fp in fetched_points}

        merged_texts = {}
        for p in points:
            center_id = p.id
            full_text_list = []
            for i in range(window_size, 0, -1):
                t = text_map.get(center_id - i)
                if t: full_text_list.append(t)
            
            full_text_list.append(text_map.get(center_id, ""))
            
            for i in range(1, window_size + 1):
                t = text_map.get(center_id + i)
                if t: full_text_list.append(t)
            
            merged_texts[center_id] = " ".join(full_text_list)
            
        return merged_texts

    def _save_debug_log(self, query, expanded_query, scanned_points, final_docs):
        log_path = "debug_search_log.txt"
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(f"=== Debug Log (Hybrid Search) ===\n")
            f.write(f"Original Query: {query}\n")
            f.write(f"Expanded Query: {expanded_query}\n\n")
            
            f.write(f"=== 1. Hybrid Retrieval Candidates (RRF Top {len(scanned_points)}) ===\n")
            for i, p in enumerate(scanned_points):
                f.write(f"[{i+1}] ID: {p.id} | RRF Score: {p.score:.6f}\n")
                f.write(f"    Text: {p.payload['text'][:100]}...\n")
            
            f.write(f"\n=== 2. Reranker Selected (Top {len(final_docs)}) ===\n")
            for i, doc in enumerate(final_docs):
                p = doc.payload
                f.write(f"[{i+1}] ID: {p.id} | Rerank Score: {doc.score:.4f}\n")
                f.write(f"    Full Context used:\n{doc.full_context_text[:200]}...\n\n")
        
        print(f"ğŸ“ [Log] ê²€ìƒ‰ ìƒì„¸ ë‚´ìš©ì´ '{log_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def run(self, query, window_size=0):
        print(f"\nğŸš€ [Pipeline] ì²˜ë¦¬ ì‹œì‘: '{query}' (Hybrid Mode, Window: {window_size})")
        
        intent, cid = self.router.route(query)
        print(f"ğŸš¦ [Router] ë¶„ì„ ê²°ê³¼: Intent='{intent}', Chapter='{cid}'")
        
        # ğŸ“Œ Case A: ì±•í„° ìš”ì•½ (Lookup)
        if intent == "lookup_chapter" and cid:
            # 1. ì±•í„° ì¤„ê±°ë¦¬ ê°€ì ¸ì˜¤ê¸°
            chapter_summary = self.lookup.get(f"chapter_{cid}", "ì •ë³´ ì—†ìŒ")
            
            # 2. ì‚¬ê±´(Event) ì¤„ê±°ë¦¬ ê°€ì ¸ì˜¤ê¸° (ë§¤í•‘ í™œìš©)
            event_id = self.chapter_event_map.get(cid)
            event_summary = ""
            if event_id:
                event_summary = self.lookup.get(f"event_{event_id}", "")
            
            # 3. Context ì¡°ë¦½ (ì‚¬ê±´ ìš”ì•½ + ì±•í„° ìš”ì•½)
            full_context = ""
            if event_summary:
                full_context += f"[Related Event Summary (Event {event_id})]\n{event_summary}\n\n"
            full_context += f"[Target Chapter Summary (Chapter {cid})]\n{chapter_summary}"

            # 4. í”„ë¡¬í”„íŠ¸ ìƒì„± (RAG_GENERATION_CHAPTER ì‚¬ìš©)
            formatted_prompt = RAG_GENERATION_CHAPTER.format(
                user_query=query,
                # ğŸ‘‡ [ìˆ˜ì •] ì¸ë¬¼ ì •ë³´ë¥¼ ì „ì²´ í†µì§¸ë¡œ ì£¼ì… (raw_character_info)
                character_info=self.raw_character_info,
                global_summary=self.lookup.get("global", ""),
                # ğŸ‘‡ [ìˆ˜ì •] context_summaries ìœ„ì¹˜ì— ì‚¬ê±´+ì±•í„° ìš”ì•½ ì£¼ì…
                context_summaries=full_context 
            )
            # ğŸ‘‡ [ìˆ˜ì •] RAG_SYSTEM_CHAPTER ì‚¬ìš©
            return self.llm.ask(RAG_SYSTEM_CHAPTER, formatted_prompt)

        # ğŸ“Œ Case B: ì¼ë°˜ ê²€ìƒ‰ (Search)
        search_query = self.expander.expand(query)
        print(f"ğŸ” [Expander] í™•ì¥ëœ ì¿¼ë¦¬: '{search_query}'")

        scanned_points = self.hybrid_search(query, search_query, top_k=settings.rag["top_k_retrieve"])
        
        if not scanned_points: return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        window_texts = self._fetch_window_context(scanned_points, window_size=window_size)

        candidates = []
        for hit in scanned_points:
            p = hit.payload
            center_id = hit.id
            
            extended_text = window_texts.get(center_id, p['text'])
            c_txt = self.lookup.get(f"chapter_{p['chapter_id']}", "")
            e_txt = self.lookup.get(f"event_{p.get('event_id')}", "")
            
            full_context_for_rerank = (
                f"{extended_text}\n\n"
                f"[ì°¸ê³  - ì‚¬ê±´: {e_txt}]\n"
                f"[ì°¸ê³  - ì „ì²´: {c_txt}]"
            )
            candidates.append(SearchResult(payload=ScenePayload(**p), full_context_text=full_context_for_rerank))

        final_docs = self.reranker.rerank(query=query, docs=candidates, top_k=settings.rag["top_k_final"])
        self._save_debug_log(query, search_query, scanned_points, final_docs)
        print(f"ğŸ¯ [Reranker] {len(scanned_points)}ê°œ -> {len(final_docs)}ê°œ ì„ ì •")

        events = set()
        chapters = set()
        scenes = []
        
        for doc in final_docs:
            p = doc.payload
            scenes.append(f"- [{p.chapter_id}í™” {p.scene_idx}ì»·] {p.text}")
            
            c_full = self.lookup.get(f"chapter_{p.chapter_id}", "")
            if c_full: chapters.add(f"- [Ch.{p.chapter_id}] {c_full}")
            if p.event_id:
                e_full = self.lookup.get(f"event_{p.event_id}", "")
                if e_full: events.add(f"- [Event] {e_full}")

        # ğŸ‘‡ [ìˆ˜ì •] RAG_GENERATION_SCENE ì‚¬ìš©
        final_prompt = RAG_GENERATION_SCENE.format(
            # ğŸ‘‡ [ìˆ˜ì •] ì¸ë¬¼ ì •ë³´ë¥¼ ì „ì²´ í†µì§¸ë¡œ ì£¼ì… (raw_character_info)
            character_info=self.raw_character_info,
            global_summary=self.lookup.get("global", ""),
            context_summaries="\n".join(events) + "\n" + "\n".join(chapters),
            scene_details="\n".join(scenes),
            user_query=query
        )

        # ğŸ‘‡ [ìˆ˜ì •] RAG_SYSTEM_SCENE ì‚¬ìš©
        return self.llm.ask(RAG_SYSTEM_SCENE, final_prompt)