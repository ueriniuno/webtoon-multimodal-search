{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Init"
      ],
      "metadata": {
        "id": "FRArDCgwIwzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "w5HR3WhrI0Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c30e7e38"
      },
      "source": [
        "!unzip -q \"/content/drive/MyDrive/BOAZ_/total.zip\" -d \"/content/drive/MyDrive/BOAZ_\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5fc306b"
      },
      "source": [
        "!zip -r \"/content/drive/MyDrive/BOAZ_/total_prc.zip\" \"/content/drive/MyDrive/BOAZ_/total_processed\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ë°ì´í„° ì²˜ë¦¬"
      ],
      "metadata": {
        "id": "cKf724Bdymck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gemini testìš© ë°ì´í„° ìë¥´ê¸°"
      ],
      "metadata": {
        "id": "htEdljcVycsA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCYWkbhmEd9f"
      },
      "outputs": [],
      "source": [
        "pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# --- ì„¤ì • ë³€ìˆ˜ ---\n",
        "INPUT_DIR = \"/content/drive/MyDrive/BOAZ_/total\"          # ì´ë¯¸ì§€ê°€ ë“¤ì–´ìˆëŠ” í´ë” ì´ë¦„\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/BOAZ_/total_processed\"   # ë¶„í• ëœ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  í´ë” ì´ë¦„\n",
        "SPLIT_COUNT = 13                    # ì´ë¯¸ì§€ ë¶„í•  ê°œìˆ˜ (13ë“±ë¶„)\n",
        "\n",
        "def split_image_into_N_vertical_parts(image_path, output_dir, N):\n",
        "    \"\"\"\n",
        "    ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ ì„¸ë¡œ ë°©í–¥ìœ¼ë¡œ Nê°œì˜ ì¡°ê°(ë†’ì´ ë¶„í• )ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. ì´ë¯¸ì§€ ë¡œë“œ\n",
        "        img = Image.open(image_path)\n",
        "\n",
        "        # 2. ì´ë¯¸ì§€ ì •ë³´\n",
        "        width, height = img.size\n",
        "\n",
        "        # 3. ê° ì¡°ê°ì˜ ë†’ì´ ê³„ì‚° (ì •ìˆ˜ ë‚˜ëˆ—ì…ˆ)\n",
        "        part_height = height // N\n",
        "\n",
        "        # 4. íŒŒì¼ ì´ë¦„ ë° í™•ì¥ì ë¶„ë¦¬\n",
        "        base_name, ext = os.path.splitext(os.path.basename(image_path))\n",
        "\n",
        "        print(f\"\\n[ì²˜ë¦¬ ì¤‘] íŒŒì¼: {os.path.basename(image_path)} (í¬ê¸°: {width}x{height})\")\n",
        "        print(f\"  -> ê° ì¡°ê° ë†’ì´: ì•½ {part_height} í”½ì…€\")\n",
        "\n",
        "        # 5. Nê°œì˜ ì¡°ê° ìë¥´ê¸° ë° ì €ì¥\n",
        "        for i in range(N):\n",
        "            # ië²ˆì§¸ ì¡°ê°ì˜ ìœ„ìª½ ê²½ê³„ (Top)\n",
        "            top = i * part_height\n",
        "\n",
        "            # ì•„ë˜ìª½ ê²½ê³„ (Bottom): ë§ˆì§€ë§‰ ì¡°ê°ì€ ë‚˜ë¨¸ì§€ ë†’ì´ë¥¼ ëª¨ë‘ í¬í•¨í•˜ì—¬ ì •í™•í•œ ë¶„í•  ë³´ì¥\n",
        "            if i == N - 1:\n",
        "                bottom = height\n",
        "            else:\n",
        "                bottom = (i + 1) * part_height\n",
        "\n",
        "            # ì´ë¯¸ì§€ ìë¥´ê¸° (crop): (left, top, right, bottom)\n",
        "            cropped_img = img.crop((0, top, width, bottom))\n",
        "\n",
        "            # ìƒˆ íŒŒì¼ ì´ë¦„ ì„¤ì • (ì˜ˆ: image_split_v12_01.png)\n",
        "            output_filename = os.path.join(output_dir, f\"{base_name}_split_v{N}_{i+1:02d}{ext}\")\n",
        "\n",
        "            # íŒŒì¼ ì €ì¥\n",
        "            cropped_img.save(output_filename)\n",
        "            print(f\"  -> ì €ì¥ ì™„ë£Œ: {os.path.basename(output_filename)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ ì˜¤ë¥˜ ë°œìƒ: {image_path} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ - {e}\")\n",
        "\n",
        "def process_images_in_target_directory():\n",
        "    \"\"\"\n",
        "    INPUT_DIRì— ì§€ì •ëœ í´ë”ì˜ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì•„ ì„¸ë¡œë¡œ SPLIT_COUNT ë“±ë¶„í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "\n",
        "    # ì²˜ë¦¬í•  ì´ë¯¸ì§€ íŒŒì¼ í™•ì¥ì ëª©ë¡ (ì†Œë¬¸ì)\n",
        "    image_extensions = ('*.png', '*.jpg', '*.jpeg')\n",
        "\n",
        "    # ì¶œë ¥ í´ë” ìƒì„±\n",
        "    output_path = OUTPUT_DIR # os.path.join(os.getcwd(), OUTPUT_DIR) # Modified to use absolute path directly\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "        print(f\"ì¶œë ¥ í´ë” ìƒì„±: {output_path}\")\n",
        "\n",
        "    print(f\"\\n--- ì´ë¯¸ì§€ ì„¸ë¡œ {SPLIT_COUNT}ë“±ë¶„ ì¼ê´„ ì²˜ë¦¬ ì‹œì‘ (ëŒ€ìƒ í´ë”: {INPUT_DIR}) ---\")\n",
        "\n",
        "    found_count = 0\n",
        "\n",
        "    # INPUT_DIR í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ì„ ê²€ìƒ‰\n",
        "    for ext in image_extensions:\n",
        "        search_path = os.path.join(INPUT_DIR, ext)\n",
        "        for image_path in glob.glob(search_path):\n",
        "            split_image_into_N_vertical_parts(image_path, output_path, SPLIT_COUNT)\n",
        "            found_count += 1\n",
        "\n",
        "    if found_count == 0:\n",
        "        print(f\"\\nâš ï¸ ì˜¤ë¥˜: í´ë” '{INPUT_DIR}'ì—ì„œ ì²˜ë¦¬í•  ì´ë¯¸ì§€ íŒŒì¼(png, jpg, jpeg)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        print(\"   - í´ë” ì´ë¦„ì´ ë§ëŠ”ì§€, ì´ë¯¸ì§€ê°€ í´ë” ì•ˆì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "    else:\n",
        "        print(f\"\\nâœ… ì´ {found_count}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# --- ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰ ---\n",
        "process_images_in_target_directory()"
      ],
      "metadata": {
        "id": "R369cwG5uS6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì½”ë“œ êµ¬í˜„"
      ],
      "metadata": {
        "id": "ABLaZw-xyrTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLIP ì„ë² ë”© ë³€í™˜ ë° ì €ì¥, í…ŒìŠ¤íŠ¸ (Retreival)"
      ],
      "metadata": {
        "id": "JDBYd6_MytVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "!pip install -q transformers torch pillow chromadb"
      ],
      "metadata": {
        "id": "nFnTDF0YTVoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "# ==========================================\n",
        "# 1. ì„¤ì • ë° ëª¨ë¸ ë¡œë“œ\n",
        "# ==========================================\n",
        "\n",
        "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# CLIP ëª¨ë¸ ë¡œë“œ (OpenAIì˜ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©)\n",
        "model_id = \"openai/clip-vit-base-patch32\"\n",
        "model = CLIPModel.from_pretrained(model_id).to(device)\n",
        "processor = CLIPProcessor.from_pretrained(model_id)\n",
        "\n",
        "# ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ë©”ëª¨ë¦¬ ëª¨ë“œ - Colab ì„¸ì…˜ ëë‚˜ë©´ ì‚¬ë¼ì§)\n",
        "# ë°ì´í„°ë¥¼ ì˜êµ¬ ì €ì¥í•˜ë ¤ë©´: chromadb.PersistentClient(path=\"./my_db\") ì‚¬ìš©\n",
        "client = chromadb.Client()\n",
        "\n",
        "# ì»¬ë ‰ì…˜ ìƒì„± (ì´ë¯¸ ìˆë‹¤ë©´ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±)\n",
        "collection_name = \"webtoon_rag\"\n",
        "try:\n",
        "    client.delete_collection(name=collection_name)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# CLIPì€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ distance metricì„ 'cosine'ìœ¼ë¡œ ì„¤ì •\n",
        "collection = client.create_collection(\n",
        "    name=collection_name,\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "print(\"âœ… ëª¨ë¸ ë¡œë“œ ë° DB ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. ì„ë² ë”© í•¨ìˆ˜ ì •ì˜\n",
        "# ==========================================\n",
        "\n",
        "def get_image_embedding(image_path):\n",
        "    try:\n",
        "        image = Image.open(image_path)\n",
        "        # CLIP í”„ë¡œì„¸ì„œë¥¼ í†µí•´ ì „ì²˜ë¦¬ (ì´ë¯¸ì§€ -> í…ì„œ)\n",
        "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # ì„ë² ë”© ì¶”ì¶œ\n",
        "        with torch.no_grad():\n",
        "            image_features = model.get_image_features(**inputs)\n",
        "\n",
        "        # ì •ê·œí™” (Normalization) - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì„±ëŠ¥ í–¥ìƒ\n",
        "        image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)\n",
        "\n",
        "        # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜\n",
        "        return image_features.cpu().numpy()[0].tolist()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# ==========================================\n",
        "# 3. ì´ë¯¸ì§€ í´ë” ìˆœíšŒ ë° DB ì €ì¥\n",
        "# ==========================================\n",
        "\n",
        "# âš ï¸ [ì¤‘ìš”] ë¶„í• ëœ ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”!\n",
        "# ì˜ˆ: Colabì— 'images' í´ë”ë¥¼ ë§Œë“¤ê³  ì—…ë¡œë“œí–ˆë‹¤ë©´ \"./images\"\n",
        "IMAGE_FOLDER_PATH = \"/content/drive/MyDrive/BOAZ_/total_processed\"\n",
        "\n",
        "# í´ë”ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)\n",
        "if not os.path.exists(IMAGE_FOLDER_PATH):\n",
        "    os.makedirs(IMAGE_FOLDER_PATH)\n",
        "    print(f\"âš ï¸ ê²½ê³ : '{IMAGE_FOLDER_PATH}' í´ë”ê°€ ì—†ì–´ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "# ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
        "image_files = [f for f in os.listdir(IMAGE_FOLDER_PATH) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "print(f\"ì´ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤...\")\n",
        "\n",
        "ids = []\n",
        "embeddings = []\n",
        "metadatas = []\n",
        "\n",
        "for idx, file_name in enumerate(image_files):\n",
        "    file_path = os.path.join(IMAGE_FOLDER_PATH, file_name)\n",
        "\n",
        "    # 2ë‹¨ê³„: ì„ë² ë”© ì¶”ì¶œ\n",
        "    embedding = get_image_embedding(file_path)\n",
        "\n",
        "    if embedding is not None:\n",
        "        ids.append(file_name) # IDëŠ” íŒŒì¼ëª…ìœ¼ë¡œ ì„¤ì •\n",
        "        embeddings.append(embedding)\n",
        "        # ë©”íƒ€ë°ì´í„°ì— ì›ë³¸ ê²½ë¡œ ì €ì¥ (ë‚˜ì¤‘ì— ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ë•Œ í•„ìš”)\n",
        "        metadatas.append({\"source\": \"webtoon\", \"file_path\": file_path})\n",
        "\n",
        "    if (idx + 1) % 10 == 0:\n",
        "        print(f\"{idx + 1}ê°œ ì²˜ë¦¬ ì™„ë£Œ...\")\n",
        "\n",
        "# 3ë‹¨ê³„: ChromaDBì— ì €ì¥\n",
        "if ids:\n",
        "    collection.add(\n",
        "        ids=ids,\n",
        "        embeddings=embeddings,\n",
        "        metadatas=metadatas\n",
        "    )\n",
        "    print(f\"\\nğŸ‰ ì„±ê³µ! ì´ {len(ids)}ê°œì˜ ì›¹íˆ° ì»·ì´ Vector DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "else:\n",
        "    print(\"\\nâŒ ì €ì¥í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. í´ë” ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
      ],
      "metadata": {
        "id": "gdXmEdLSTXlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. í…ìŠ¤íŠ¸ë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰ (Retrieval í…ŒìŠ¤íŠ¸)\n",
        "# ==========================================\n",
        "\n",
        "def search_webtoon(query_text, top_k=3):\n",
        "    # 1. í…ìŠ¤íŠ¸ ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\n",
        "    inputs = processor(text=[query_text], return_tensors=\"pt\", padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        text_features = model.get_text_features(**inputs)\n",
        "\n",
        "    # ì •ê·œí™”\n",
        "    text_features = text_features / text_features.norm(p=2, dim=-1, keepdim=True)\n",
        "    query_embedding = text_features.cpu().numpy()[0].tolist()\n",
        "\n",
        "    # 2. Vector DBì—ì„œ ìœ ì‚¬í•œ ì´ë¯¸ì§€ ê²€ìƒ‰\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_embedding],\n",
        "        n_results=top_k\n",
        "    )\n",
        "\n",
        "    return results\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸\n",
        "query = \"Pink shirts, short haired woman\"\n",
        "\n",
        "print(f\"ğŸ” ì§ˆë¬¸: '{query}'\")\n",
        "results = search_webtoon(query)\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "print(\"\\n[ê²€ìƒ‰ ê²°ê³¼]\")\n",
        "for i in range(len(results['ids'][0])):\n",
        "    file_name = results['ids'][0][i]\n",
        "    distance = results['distances'][0][i] # ê±°ë¦¬ê°€ ê°€ê¹Œìš¸ìˆ˜ë¡(0ì— ê°€ê¹Œìš¸ìˆ˜ë¡) ìœ ì‚¬í•¨ (cosine distance)\n",
        "    print(f\"{i+1}ìˆœìœ„: {file_name} (ê±°ë¦¬: {distance:.4f})\")\n",
        "\n",
        "    # Colabì—ì„œ ì´ë¯¸ì§€ ë°”ë¡œ ë³´ê¸°\n",
        "    from IPython.display import display\n",
        "    img_path = results['metadatas'][0][i]['file_path']\n",
        "    display(Image.open(img_path).resize((200, 200))) # ë³´ê¸° ì¢‹ê²Œ ë¦¬ì‚¬ì´ì§•\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "7m0NtujxUmIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ë‹¤êµ­ì–´ CLIP ver code"
      ],
      "metadata": {
        "id": "YVhFygmkyiM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers chromadb"
      ],
      "metadata": {
        "id": "HlpuZxyzXvlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "\n",
        "# ==========================================\n",
        "# 1. ëª¨ë¸ ë° DB ì„¤ì •\n",
        "# ==========================================\n",
        "print(\"ğŸš€ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
        "model = SentenceTransformer('clip-ViT-B-32-multilingual-v1')\n",
        "\n",
        "client = chromadb.Client()\n",
        "collection_name = \"webtoon_kor_fixed\"\n",
        "\n",
        "# ê¸°ì¡´ ì»¬ë ‰ì…˜ ì´ˆê¸°í™”\n",
        "try:\n",
        "    client.delete_collection(name=collection_name)\n",
        "except:\n",
        "    pass\n",
        "collection = client.create_collection(name=collection_name)\n",
        "\n",
        "# ==========================================\n",
        "# 2. ì´ë¯¸ì§€ ë°°ì¹˜ ì²˜ë¦¬ (Batch Processing) - í•µì‹¬! â­\n",
        "# ==========================================\n",
        "IMAGE_FOLDER_PATH = \"/content/drive/MyDrive/BOAZ_/total_processed\"\n",
        "\n",
        "if not os.path.exists(IMAGE_FOLDER_PATH):\n",
        "    print(f\"âŒ ê²½ë¡œ ì˜¤ë¥˜: '{IMAGE_FOLDER_PATH}' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "else:\n",
        "    image_files = [f for f in os.listdir(IMAGE_FOLDER_PATH) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    total_files = len(image_files)\n",
        "    print(f\"ğŸ“‚ ì´ {total_files}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "    # ë°°ì¹˜ ì„¤ì • (í•œ ë²ˆì— 32ì¥ì”© ì²˜ë¦¬)\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    # ì„ì‹œ ì €ì¥ì†Œ\n",
        "    batch_images = []\n",
        "    batch_ids = []\n",
        "    batch_metadatas = []\n",
        "\n",
        "    for idx, file_name in enumerate(image_files):\n",
        "        file_path = os.path.join(IMAGE_FOLDER_PATH, file_name)\n",
        "\n",
        "        try:\n",
        "            # 1. ì´ë¯¸ì§€ ë¡œë“œ ë° RGB ë³€í™˜ (PNG íˆ¬ëª…ë„ ë¬¸ì œ ë°©ì§€)\n",
        "            img = Image.open(file_path).convert('RGB')\n",
        "\n",
        "            batch_images.append(img)\n",
        "            batch_ids.append(file_name)\n",
        "            batch_metadatas.append({\"file_path\": file_path})\n",
        "\n",
        "            # 2. ë°°ì¹˜ê°€ ê½‰ ì°¼ê±°ë‚˜ ë§ˆì§€ë§‰ ì´ë¯¸ì§€ì¼ ë•Œ -> ì¸ì½”ë”© ì‹¤í–‰\n",
        "            if len(batch_images) >= BATCH_SIZE or idx == total_files - 1:\n",
        "\n",
        "                # [í•µì‹¬ ìˆ˜ì •] ë¦¬ìŠ¤íŠ¸ í˜•íƒœ(batch_images)ë¡œ ë„˜ê²¨ì¤ë‹ˆë‹¤.\n",
        "                embeddings = model.encode(batch_images).tolist()\n",
        "\n",
        "                # DB ì €ì¥\n",
        "                collection.add(\n",
        "                    ids=batch_ids,\n",
        "                    embeddings=embeddings,\n",
        "                    metadatas=batch_metadatas\n",
        "                )\n",
        "\n",
        "                print(f\"âœ… {idx + 1}/{total_files} ì €ì¥ ì™„ë£Œ\")\n",
        "\n",
        "                # ë°°ì¹˜ ì´ˆê¸°í™”\n",
        "                batch_images = []\n",
        "                batch_ids = []\n",
        "                batch_metadatas = []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Error processing {file_name}: {e}\")\n",
        "            # ì—ëŸ¬ë‚œ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ë°°ì¹˜ì—ì„œ ì œì™¸í•˜ê³  ê³„ì† ì§„í–‰\n",
        "            if len(batch_images) > len(batch_ids):\n",
        "                batch_images.pop()\n",
        "\n",
        "    print(\"\\nğŸ‰ ëª¨ë“  ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ!\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
        "# ==========================================\n",
        "def search_korean(query_text):\n",
        "    print(f\"\\nğŸ” ê²€ìƒ‰ì–´: '{query_text}'\")\n",
        "    # í…ìŠ¤íŠ¸ë„ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì£¼ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.\n",
        "    query_emb = model.encode([query_text]).tolist()\n",
        "\n",
        "    results = collection.query(\n",
        "        query_embeddings=query_emb,\n",
        "        n_results=3\n",
        "    )\n",
        "\n",
        "    for i in range(len(results['ids'][0])):\n",
        "        file_name = results['ids'][0][i]\n",
        "        distance = results['distances'][0][i]\n",
        "        path = results['metadatas'][0][i]['file_path']\n",
        "\n",
        "        print(f\"[{i+1}ìœ„] {file_name} (ê±°ë¦¬: {distance:.4f})\")\n",
        "        try:\n",
        "            display(Image.open(path).resize((200, 200)))\n",
        "        except:\n",
        "            print(\"ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "# ë°”ë¡œ í…ŒìŠ¤íŠ¸ í•´ë³´ì„¸ìš”!\n",
        "search_korean(\"í•‘í¬ ì…”ì¸  ì…ì€ ì—¬ì\")\n",
        "search_korean(\"ë„¥íƒ€ì´ ë§¨ ë‚¨ì\")"
      ],
      "metadata": {
        "id": "GLfSTsqpX6kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MzDhgAiFZqYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# text OCR ì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬\n"
      ],
      "metadata": {
        "id": "YCPvbfV1w3iL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def extract_text_regions(image_path, save_dir, padding=20):\n",
        "    \"\"\"\n",
        "    ì›¹íˆ° ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸(ë§í’ì„ ) êµ¬ì—­ë§Œ ê°ì§€í•˜ì—¬ ì˜ë¼ë‚´ëŠ” í•¨ìˆ˜\n",
        "    Args:\n",
        "        image_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ\n",
        "        save_dir: ì €ì¥í•  í´ë”\n",
        "        padding: í…ìŠ¤íŠ¸ ë°•ìŠ¤ ì£¼ë³€ì— ì¤„ ì—¬ë°± (px)\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. ì´ë¯¸ì§€ ë¡œë“œ\n",
        "    img_array = np.fromfile(image_path, np.uint8)\n",
        "    img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
        "\n",
        "    if img is None:\n",
        "        return\n",
        "\n",
        "    file_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "    # 2. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 3. ì—£ì§€ ê²€ì¶œ ë° ì´ì§„í™” (ê¸€ì”¨ë¥¼ í•˜ì–—ê²Œ, ë°°ê²½ì„ ê²€ê²Œ)\n",
        "    # ì ì‘í˜• ì´ì§„í™”(Adaptive Threshold)ë¥¼ ì“°ë©´ ê·¸ë¦¼ì ì§„ ë§í’ì„ ë„ ì˜ ì°¾ìŠµë‹ˆë‹¤.\n",
        "    binary = cv2.adaptiveThreshold(\n",
        "        gray, 255,\n",
        "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "        cv2.THRESH_BINARY_INV,\n",
        "        11, 5\n",
        "    )\n",
        "\n",
        "    # 4. ëª¨í´ë¡œì§€ ì—°ì‚° (íŒ½ì°½) - í•µì‹¬! â­\n",
        "    # ê¸€ìë“¤ì„ ëš±ëš±í•˜ê²Œ ë§Œë“¤ì–´ì„œ í•œ ë©ì–´ë¦¬ë¡œ ë­‰ì¹©ë‹ˆë‹¤.\n",
        "    # ì»¤ë„ ì‚¬ì´ì¦ˆ (15, 3)ì€ ê°€ë¡œë¡œ ê¸´ í…ìŠ¤íŠ¸(ë¬¸ì¥)ë¥¼ ì˜ ë­‰ì¹˜ê²Œ í•©ë‹ˆë‹¤.\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 5))\n",
        "    dilated = cv2.dilate(binary, kernel, iterations=3)\n",
        "\n",
        "    # 5. ìœ¤ê³½ì„ (ë©ì–´ë¦¬) ì°¾ê¸°\n",
        "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    count = 0\n",
        "    img_height, img_width = img.shape[:2]\n",
        "\n",
        "    # ìœ¤ê³½ì„  ìˆœì„œë¥¼ ìœ„ì—ì„œ ì•„ë˜ë¡œ ì •ë ¬ (ìŠ¤í¬ë¡¤ ìˆœì„œ ìœ ì§€)\n",
        "    bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
        "    bounding_boxes.sort(key=lambda x: x[1]) # yì¢Œí‘œ ê¸°ì¤€ ì •ë ¬\n",
        "\n",
        "    for (x, y, w, h) in bounding_boxes:\n",
        "\n",
        "        # 6. í•„í„°ë§ (ë„ˆë¬´ ì‘ê±°ë‚˜ ì´ìƒí•œ ë¹„ìœ¨ì€ ë²„ë¦¼)\n",
        "        # ì˜ˆ: ë„ˆë¹„ê°€ ë„ˆë¬´ ì¢ê±°ë‚˜(ì„¸ë¡œì„ ), ë†’ì´ê°€ ë„ˆë¬´ ë‚®ê±°ë‚˜(ì ), í™”ë©´ ì „ì²´ê±°ë‚˜\n",
        "        if w < 20 or h < 20: continue # ë„ˆë¬´ ì‘ì€ ì \n",
        "        if w > img_width * 0.9 and h > img_height * 0.9: continue # ì´ë¯¸ì§€ ì „ì²´\n",
        "\n",
        "        # ë¹„ìœ¨ í•„í„° (ë§í’ì„ ì€ ë³´í†µ ë©ì–´ë¦¬ í˜•íƒœ)\n",
        "        aspect_ratio = w / float(h)\n",
        "        if aspect_ratio < 0.2 or aspect_ratio > 10: continue\n",
        "\n",
        "        # 7. íŒ¨ë”©ì„ ì¤˜ì„œ ë„‰ë„‰í•˜ê²Œ ìë¥´ê¸° (ê¸€ì ì˜ë¦¼ ë°©ì§€)\n",
        "        x1 = max(0, x - padding)\n",
        "        y1 = max(0, y - padding)\n",
        "        x2 = min(img_width, x + w + padding)\n",
        "        y2 = min(img_height, y + h + padding)\n",
        "\n",
        "        roi = img[y1:y2, x1:x2]\n",
        "\n",
        "        # ì €ì¥\n",
        "        save_path = os.path.join(save_dir, f\"{file_name}_text_{count:03d}.jpg\")\n",
        "        is_success, im_buf_arr = cv2.imencode(\".jpg\", roi)\n",
        "        if is_success:\n",
        "            im_buf_arr.tofile(save_path)\n",
        "            count += 1\n",
        "\n",
        "    print(f\"âœ… {file_name}: í…ìŠ¤íŠ¸ êµ¬ì—­ {count}ê°œ ì¶”ì¶œ ì™„ë£Œ\")\n",
        "\n",
        "# ==========================================\n",
        "# ì‹¤í–‰\n",
        "# ==========================================\n",
        "INPUT_DIR = \"/content/drive/MyDrive/BOAZ_/raw_webtoons\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/BOAZ_/ocr_crops\"\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "files = [f for f in os.listdir(INPUT_DIR) if f.lower().endswith(('.jpg', '.png'))]\n",
        "\n",
        "for f in files:\n",
        "    path = os.path.join(INPUT_DIR, f)\n",
        "    extract_text_regions(path, OUTPUT_DIR, padding=30)"
      ],
      "metadata": {
        "id": "b_XWnkqUw-Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JoyCaption test"
      ],
      "metadata": {
        "id": "97FBMT2SIG8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ê¸°ì¡´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°•ì œ ì‚­ì œ\n",
        "!pip uninstall -y transformers accelerate bitsandbytes\n",
        "\n",
        "# 2. í˜¸í™˜ì„±ì´ ê²€ì¦ëœ ë²„ì „ìœ¼ë¡œ ì¬ì„¤ì¹˜\n",
        "!pip install -q -U transformers==4.46.3 accelerate bitsandbytes \"pillow<11.0.0\""
      ],
      "metadata": {
        "id": "vl8WW32NIo6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import gc\n",
        "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
        "from PIL import Image\n",
        "\n",
        "# 1. í™˜ê²½ ì •ë¦¬\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model_id = \"fancyfeast/llama-joycaption-beta-one-hf-llava\"\n",
        "\n",
        "# 2. 8-bit ë¡œë“œ (T4 GPUì—ì„œ ê°€ì¥ í˜¸í™˜ì„±ì´ ë†’ìŒ)\n",
        "print(\"ğŸš€ [System] ëª¨ë¸ ë¡œë”© ë° íƒ€ì… ìµœì í™” ì‹œì‘...\")\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "model = LlavaForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    load_in_8bit=True,\n",
        "    device_map={\"\": 0},\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# ëª¨ë¸ì˜ ì‹¤ì œ ì—°ì‚° íƒ€ì…ì„ ë³€ìˆ˜ì— ì €ì¥ (í•µì‹¬)\n",
        "target_dtype = model.dtype\n",
        "print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! ì—°ì‚° ì •ë°€ë„: {target_dtype}\")\n",
        "\n",
        "# 3. ìº¡ì…˜ ìƒì„± í•¨ìˆ˜ (ê°•ì œ ìºìŠ¤íŒ… ë¡œì§ í¬í•¨)\n",
        "def generate_webtoon_caption(image_path):\n",
        "    raw_image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    prompt = \"Describe this webtoon panel in detail. Focus on the character's facial expression, the emotional vibe of the scene, and any notable artistic styles.\"\n",
        "    formatted_prompt = f\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\n<image>\\n{prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
        "\n",
        "    # í…ì„œ ìƒì„±\n",
        "    inputs = processor(text=[formatted_prompt], images=[raw_image], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # [í•µì‹¬] ëª¨ë“  ì…ë ¥ í…ì„œë¥¼ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ íƒ€ì…(target_dtype)ìœ¼ë¡œ ê°•ì œ ë³€í™˜\n",
        "    # FloatTensor(32) -> HalfTensor(16) ë³€í™˜ì„ ìˆ˜í–‰í•˜ì—¬ ì¶©ëŒ ë°©ì§€\n",
        "    for k, v in inputs.items():\n",
        "        if isinstance(v, torch.Tensor) and torch.is_floating_point(v):\n",
        "            inputs[k] = v.to(target_dtype)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=300,\n",
        "            do_sample=True,\n",
        "            temperature=0.6,\n",
        "            top_p=0.9,\n",
        "            eos_token_id=processor.tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    decoded = processor.decode(output[0], skip_special_tokens=True)\n",
        "    return decoded.split(\"assistant\")[-1].strip()\n",
        "\n",
        "# 4. ì‹¤í–‰\n",
        "target_path = \"/content/drive/MyDrive/BOAZ_/total_processed/screencapture-comic-naver-webtoon-detail-2025-11-29-12_37_14-4_split_v13_01.png\"\n",
        "\n",
        "if os.path.exists(target_path):\n",
        "    print(f\"\\nğŸ” ë¶„ì„ ì‹œì‘: {os.path.basename(target_path)}\")\n",
        "    try:\n",
        "        # GPU ìºì‹œ ë¹„ìš°ê³  ì‹¤í–‰\n",
        "        torch.cuda.empty_cache()\n",
        "        result = generate_webtoon_caption(target_path)\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"[JoyCaption ê²°ê³¼]\\n{result}\")\n",
        "        print(\"=\"*50)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ìµœì¢… ì‹œë„ ì‹¤íŒ¨: {e}\")\n",
        "        # ì‹¤íŒ¨ ì‹œ íƒ€ì… ì •ë³´ ì¶œë ¥ (ë””ë²„ê¹…ìš©)\n",
        "        print(f\"DEBUG: Input dtype: {inputs['pixel_values'].dtype if 'inputs' in locals() else 'N/A'}\")\n",
        "        print(f\"DEBUG: Model dtype: {model.dtype}\")"
      ],
      "metadata": {
        "id": "3dt6xcQNISTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/BOAZ_/total_processed/screencapture-comic-naver-webtoon-detail-2025-11-29-12_37_14-4_split_v13_01.png\"\n",
        "\n",
        "if os.path.exists(image_path):\n",
        "    result = generate_caption(image_path, \"Describe this webtoon scene in detail, focusing on expressions and atmosphere.\")\n",
        "    print(\"\\n[ìº¡ì…˜ ê²°ê³¼]\\n\", result)\n",
        "else:\n",
        "    print(\"ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
      ],
      "metadata": {
        "id": "XPAMwBjiIfrF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}