import os
import sys
from pathlib import Path
from typing import Optional, Tuple, List, Iterable

# í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸ ë° ì—ëŸ¬ í•¸ë“¤ë§
MISSING_PACKAGES = []

try:
    import streamlit as st
except ImportError:
    MISSING_PACKAGES.append("streamlit")

try:
    from qdrant_client import QdrantClient
except ImportError:
    MISSING_PACKAGES.append("qdrant-client")

try:
    from sentence_transformers import SentenceTransformer
except ImportError:
    MISSING_PACKAGES.append("sentence-transformers")

try:
    import torch
except ImportError:
    MISSING_PACKAGES.append("torch")

if MISSING_PACKAGES:
    print("=" * 60)
    print("âŒ í•„ìˆ˜ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    print("=" * 60)
    print(f"ëˆ„ë½ëœ íŒ¨í‚¤ì§€: {', '.join(MISSING_PACKAGES)}")
    print("\nì„¤ì¹˜ ë°©ë²•:")
    print(f"  {sys.executable} -m pip install {' '.join(MISSING_PACKAGES)}")
    print("\në˜ëŠ” ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰:")
    print("  python install_dependencies.py")
    print("=" * 60)
    sys.exit(1)

import streamlit as st
import pandas as pd

try:
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

# src ëª¨ë“ˆ ì„í¬íŠ¸ (ì—ëŸ¬ í•¸ë“¤ë§)
try:
    from src import WebtoonDB, EmbeddingEngine, ExaoneLLM, RAGPipeline
    from src.config import settings
    from src.prompts import (
        RAG_GENERATION_CHAPTER,
        RAG_GENERATION_SCENE,
        RAG_SYSTEM_CHAPTER,
        RAG_SYSTEM_SCENE,
    )
except ImportError as e:
    st.error(f"âŒ ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    st.info(
        f"""
        **í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤:**
        
        í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:
        ```bash
        {sys.executable} -m pip install qdrant-client sentence-transformers transformers torch PyYAML rank-bm25 kiwipiepy
        ```
        
        ë˜ëŠ” ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰:
        ```bash
        python install_dependencies.py
        ```
        """
    )
    st.stop()


st.set_page_config(
    page_title="Webtoon RAG Pipeline Viewer",
    page_icon="ğŸ•¸ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)


_DARK_CSS = """
<style>
  html, body {
    background-color: #0e1117;
  }
  header[data-testid="stHeader"] {
    display: none;
  }
  .stApp { background: #0e1117; color: #ffffff; }
  .block-container { padding-top: 1.25rem; }
  
  /* í˜ì´ì§€ í•˜ë‹¨ ë°°ê²½ìƒ‰ í†µì¼ */
  footer {
    background-color: #0e1117 !important;
    display: none;
  }
  footer:after {
    background-color: #0e1117 !important;
  }
  .main {
    background-color: #0e1117 !important;
  }
  
  /* ì±„íŒ… ì…ë ¥ì°½ í•˜ë‹¨ ì˜ì—­ ë‹¤í¬ ëª¨ë“œ */
  .stChatInputContainer {
    background-color: #0e1117 !important;
  }
  [data-testid="stBottom"] {
    background-color: #0e1117 !important;
  }
  [data-testid="stBottomBlockContainer"] {
    background-color: #0e1117 !important;
  }
  
  /* ì‹¤ì œ ì…ë ¥ í•„ë“œë§Œ ì •í™•í•˜ê²Œ íƒ€ê²ŸíŒ… (border ì œê±°) */
  [data-testid="stChatInput"] {
    background-color: transparent !important;
  }
  
  [data-testid="stChatInput"] > div {
    background-color: #1a1c24 !important;
    border-radius: 8px !important;
    border: none !important;
  }
  
  [data-testid="stChatInput"] input,
  [data-testid="stChatInput"] textarea {
    background-color: #1a1c24 !important;
    color: #e6e6e6 !important;
    border: none !important;
  }
  
  [data-testid="stChatInput"] input:focus,
  [data-testid="stChatInput"] textarea:focus {
    background-color: #1a1c24 !important;
    border: none !important;
    box-shadow: none !important;
    outline: none !important;
  }
  
  /* ì…ë ¥ì°½ placeholder ìƒ‰ìƒ */
  [data-testid="stChatInput"] input::placeholder,
  [data-testid="stChatInput"] textarea::placeholder {
    color: rgba(230, 230, 230, 0.5) !important;
  }
  
  /* ì „ì†¡ ë²„íŠ¼(í™”ì‚´í‘œ) ìŠ¤íƒ€ì¼ */
  [data-testid="stChatInput"] button {
    background-color: #0e1117 !important;
    color: rgba(230, 230, 230, 0.7) !important;
    border: none !important;
    border-radius: 6px !important;
    padding: 8px 12px !important;
  }
  
  [data-testid="stChatInput"] button:hover {
    background-color: #1a1c24 !important;
    color: rgba(230, 230, 230, 0.9) !important;
  }
  
  [data-testid="stChatInput"] button svg {
    color: rgba(230, 230, 230, 0.7) !important;
    fill: rgba(230, 230, 230, 0.7) !important;
  }
  
  [data-testid="stChatInput"] button:hover svg {
    color: rgba(230, 230, 230, 0.9) !important;
    fill: rgba(230, 230, 230, 0.9) !important;
  }
  
  /* Streamlit footer ìˆ¨ê¸°ê¸° */
  footer[data-testid="stFooter"] {
    display: none !important;
  }
  
  /* âœ… Chat-like cards - ëª¨ë“  í•˜ìœ„ ìš”ì†Œ ê°•ì œ í°ìƒ‰ */
  .rag-card {
    background: rgba(255,255,255,0.04);
    border: 1px solid rgba(255,255,255,0.08);
    border-radius: 14px;
    padding: 14px 14px 10px 14px;
  }
  
  .rag-card,
  .rag-card *,
  .rag-card p,
  .rag-card div,
  .rag-card span {
    color: #ffffff !important;
  }
  
  .rag-title {
    font-weight: 700;
    font-size: 0.95rem;
    margin-bottom: 0.25rem;
    color: #ffffff !important;
  }
  .rag-meta {
    opacity: 0.85;
    font-size: 0.85rem;
    margin-bottom: 0.5rem;
    color: #ffffff !important;
  }
  
  /* ëª¨ë“  ì„œë¸Œí—¤ë”ë¥¼ ì™„ì „ í°ìƒ‰ìœ¼ë¡œ ë³€ê²½ */
  h3, .stSubheader, [data-testid="stSubheader"] {
    color: #ffffff !important;
  }
  
  /* Subheaderì™€ ì•„ì´ì½˜ ì •ë ¬ - assistant ë©”ì‹œì§€ ë‚´ë¶€ */
  .stChatMessage[data-testid="chat-message-assistant"] h3 {
    display: inline-block !important;
    vertical-align: middle !important;
    margin: 0 !important;
    line-height: 1.5 !important;
    color: #ffffff !important;
  }
  /* âœ… write_stream / markdown ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸ ê°•ì œ í°ìƒ‰ */
  .stChatMessage[data-testid="chat-message-assistant"]
  [data-testid="stMarkdownContainer"] *,
  .stChatMessage[data-testid="chat-message-assistant"]
  [data-testid="stMarkdownContainer"] p,
  .stChatMessage[data-testid="chat-message-assistant"]
  [data-testid="stMarkdownContainer"] span {
    color: #ffffff !important;
  }


  .stChatMessage[data-testid="chat-message-assistant"] > div {
    display: flex !important;
    align-items: flex-start !important;
  }
  
  /* âœ… Assistant ë©”ì‹œì§€ ë‚´ ëª¨ë“  ìš”ì†Œ ê°•ì œ í°ìƒ‰ */
  .stChatMessage[data-testid="chat-message-assistant"],
  .stChatMessage[data-testid="chat-message-assistant"] *,
  .stChatMessage[data-testid="chat-message-assistant"] p,
  .stChatMessage[data-testid="chat-message-assistant"] div,
  .stChatMessage[data-testid="chat-message-assistant"] span,
  .stChatMessage[data-testid="chat-message-assistant"] li {
    color: #ffffff !important;
  }
  
  /* âœ… st.caption í…ìŠ¤íŠ¸ë„ í°ìƒ‰ */
  .stCaptionContainer,
  .stCaptionContainer *,
  [data-testid="stCaptionContainer"],
  [data-testid="stCaptionContainer"] *,
  .caption,
  .caption * {
    color: rgba(255, 255, 255, 0.9) !important;
  }
  
  /* Make sidebar fit dark mode better */
  section[data-testid="stSidebar"] {
    background: #0b0f14;
    border-right: 1px solid rgba(255,255,255,0.06);
  }
  
  /* ì‚¬ì´ë“œë°” ì„œë¸Œí—¤ë”ë„ í°ìƒ‰ */
  section[data-testid="stSidebar"] h3 {
    color: #ffffff !important;
  }
  
  /* Code block background color */
  .stCodeBlock {
    background-color: #1a1c24 !important;
  }
  pre {
    background-color: #1a1c24 !important;
    color: #e6e6e6 !important;
  }
  code {
    background-color: #1a1c24 !important;
    color: #e6e6e6 !important;
  }
  
  /* âœ… YAML í‚¤ë§Œ #00dc64 */
  pre code .na {
    color: #00dc64 !important;
  }
  
  /* âœ… YAML ê°’ì€ í°ìƒ‰ */
  pre code .s, 
  pre code .s1, 
  pre code .s2,
  pre code .m,
  pre code .mi,
  pre code .mf {
    color: #ffffff !important;
  }
  
  /* Final Answer text color */
  .final-answer-text {
    color: #ffffff !important;
    background-color: #1a1c24 !important;
    padding: 1rem !important;
    border-radius: 0.5rem !important;
    border: 1px solid rgba(255, 255, 255, 0.1) !important;
    white-space: pre-wrap !important;
    font-family: inherit !important;
    line-height: 1.6 !important;
  }

</style>
"""


st.markdown(_DARK_CSS, unsafe_allow_html=True)


@st.cache_resource(show_spinner="ëª¨ë¸/DB ì´ˆê¸°í™” ì¤‘â€¦ (ìµœì´ˆ 1íšŒë§Œ ì˜¤ë˜ ê±¸ë ¤ìš”)")
def get_pipeline() -> RAGPipeline:
    """
    config/config.yaml(settings)ì„ ì°¸ì¡°í•˜ì—¬ ì»´í¬ë„ŒíŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ê³ ,
    Streamlit ì¬ì‹¤í–‰ ì‹œì—ë„ ë¦¬ì†ŒìŠ¤ë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    db = WebtoonDB()
    embedder = EmbeddingEngine()
    llm = ExaoneLLM()
    return RAGPipeline(db, embedder, llm)


def _resolve_image_path(image_file: str) -> Optional[str]:
    """
    ê²€ìƒ‰ ê²°ê³¼ payloadì˜ image_fileì„ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ í•´ì„í•©ë‹ˆë‹¤.
    - ì ˆëŒ€ê²½ë¡œë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    - ìƒëŒ€ê²½ë¡œë©´ settings.paths['data_dir'] ê¸°ì¤€ìœ¼ë¡œ ì—¬ëŸ¬ í›„ë³´ë¥¼ íƒìƒ‰
    - webtoon-multimodal-search/im í´ë”ë„ íƒìƒ‰
    """
    if not image_file:
        return None

    p = Path(image_file)
    if p.is_absolute() and p.exists():
        return str(p)

    data_dir = Path(settings.paths["data_dir"]).resolve()
    
    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œë„ íƒìƒ‰
    script_dir = Path(__file__).parent.resolve()

    candidates: List[Path] = []
    
    # 1. data_dir ê¸°ì¤€ ê²½ë¡œë“¤
    candidates.append(data_dir / image_file)
    candidates.append(data_dir / "images" / image_file)
    candidates.append(data_dir / "imgs" / image_file)
    candidates.append(data_dir / "im" / image_file)
    candidates.append(data_dir / "thumbnails" / image_file)
    candidates.append(data_dir / "scenes" / image_file)
    
    # 2. webtoon-multimodal-search/im í´ë” íƒìƒ‰ (data_dir ê¸°ì¤€)
    current = data_dir
    for _ in range(5):  # ìµœëŒ€ 5ë‹¨ê³„ ìƒìœ„ í´ë”ê¹Œì§€ íƒìƒ‰
        webtoon_im_dir = current / "webtoon-multimodal-search" / "im"
        if webtoon_im_dir.exists():
            candidates.append(webtoon_im_dir / image_file)
            # í™•ì¥ìê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„
            if p.suffix == "":
                for ext in [".png", ".jpg", ".jpeg", ".webp"]:
                    candidates.append(webtoon_im_dir / f"{image_file}{ext}")
        current = current.parent
        if current == current.parent:  # ë£¨íŠ¸ì— ë„ë‹¬
            break
    
    # 3. ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ webtoon-multimodal-search/im íƒìƒ‰
    current = script_dir
    for _ in range(5):
        webtoon_im_dir = current / "webtoon-multimodal-search" / "im"
        if webtoon_im_dir.exists():
            candidates.append(webtoon_im_dir / image_file)
            if p.suffix == "":
                for ext in [".png", ".jpg", ".jpeg", ".webp"]:
                    candidates.append(webtoon_im_dir / f"{image_file}{ext}")
        # ìƒìœ„ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
        parent_webtoon_im = current.parent / "webtoon-multimodal-search" / "im"
        if parent_webtoon_im.exists():
            candidates.append(parent_webtoon_im / image_file)
            if p.suffix == "":
                for ext in [".png", ".jpg", ".jpeg", ".webp"]:
                    candidates.append(parent_webtoon_im / f"{image_file}{ext}")
        current = current.parent
        if current == current.parent:
            break

    # 4. í™•ì¥ìê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„
    if p.suffix == "":
        for ext in [".png", ".jpg", ".jpeg", ".webp"]:
            candidates.append(data_dir / f"{image_file}{ext}")
            candidates.append(data_dir / "images" / f"{image_file}{ext}")
            candidates.append(data_dir / "im" / f"{image_file}{ext}")
            candidates.append(data_dir / "thumbnails" / f"{image_file}{ext}")

    # 5. ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íŒŒì¼ ì°¾ê¸°
    for c in candidates:
        if c.exists() and c.is_file():
            return str(c)

    return None


def _stream_text(text: str, chunk: int = 40) -> Iterable[str]:
    """LLMì´ ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë‹ˆ, UIì—ì„œë§Œ í…ìŠ¤íŠ¸ë¥¼ ë‚˜ëˆ ì„œ í˜ë ¤ë³´ëƒ…ë‹ˆë‹¤."""
    if not text:
        return
    for i in range(0, len(text), chunk):
        yield text[i : i + chunk]


def _get_webtoon_title() -> str:
    """
    ë°ì´í„°ì…‹ì´ ë‹¨ì¼ ì›¹íˆ°ì¸ ê²½ìš°ê°€ ë§ì•„ ê¸°ë³¸ íƒ€ì´í‹€ì„ ì œê³µ.
    ë°ì´í„° í´ë”ì— metadata/global_summary ë“±ì´ ìˆìœ¼ë©´ ê±°ê¸°ì„œë„ ì‹œë„í•©ë‹ˆë‹¤(ì—†ìœ¼ë©´ ê¸°ë³¸ê°’).
    """
    data_dir = Path(settings.paths["data_dir"])
    for candidate in [data_dir / "metadata.json", data_dir / "meta.json", data_dir / "global_summary.json"]:
        try:
            if candidate.exists():
                import json

                obj = json.loads(candidate.read_text(encoding="utf-8"))
                for key in ["title", "webtoon_title", "name"]:
                    v = obj.get(key)
                    if isinstance(v, str) and v.strip():
                        return v.strip()
        except Exception:
            pass
    return "Webtoon"


def run_pipeline_with_traces(pipeline: RAGPipeline, query: str, window_size: int = 0) -> dict:
    """
    src/pipeline.pyì˜ run() íë¦„ì„ ê·¸ëŒ€ë¡œ ë”°ë¼ê°€ë˜,
    UIì—ì„œ ë³´ì—¬ì¤„ ì¤‘ê°„ ê²°ê³¼(ì˜ë„/ì¬ì‘ì„±/Top5 ë¬¸ì„œ)ë¥¼ ê°™ì´ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    intent, cid = pipeline.router.route(query)

    trace = {
        "query": query,
        "intent": intent,
        "chapter_id": cid,
        "rewritten_query": None,
        "top_docs": [],
        "final_answer": "",
        "mode": "search",
    }

    # Case A: ì±•í„° ìš”ì•½(lookup)
    if intent == "lookup_chapter" and cid:
        trace["mode"] = "lookup_chapter"

        chapter_summary = pipeline.lookup.get(f"chapter_{cid}", "ì •ë³´ ì—†ìŒ")
        event_id = pipeline.chapter_event_map.get(cid)
        event_summary = pipeline.lookup.get(f"event_{event_id}", "") if event_id else ""

        full_context = ""
        if event_summary:
            full_context += f"[Related Event Summary (Event {event_id})]\n{event_summary}\n\n"
        full_context += f"[Target Chapter Summary (Chapter {cid})]\n{chapter_summary}"

        formatted_prompt = RAG_GENERATION_CHAPTER.format(
            user_query=query,
            character_info=pipeline.raw_character_info,
            global_summary=pipeline.lookup.get("global", ""),
            context_summaries=full_context,
        )
        trace["final_answer"] = pipeline.llm.ask(RAG_SYSTEM_CHAPTER, formatted_prompt)
        return trace

    # Case B: ì¼ë°˜ ê²€ìƒ‰(search)
    rewritten = pipeline.expander.expand(query)
    trace["rewritten_query"] = rewritten

    scanned_points = pipeline.hybrid_search(query, rewritten, top_k=settings.rag["top_k_retrieve"])
    if not scanned_points:
        trace["final_answer"] = "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        return trace

    window_texts = pipeline._fetch_window_context(scanned_points, window_size=window_size)

    candidates = []
    for hit in scanned_points:
        p = hit.payload
        center_id = hit.id

        extended_text = window_texts.get(center_id, p["text"])
        c_txt = pipeline.lookup.get(f"chapter_{p['chapter_id']}", "")
        e_txt = pipeline.lookup.get(f"event_{p.get('event_id')}", "")

        full_context_for_rerank = (
            f"{extended_text}\n\n"
            f"[ì°¸ê³  - ì‚¬ê±´: {e_txt}]\n"
            f"[ì°¸ê³  - ì „ì²´: {c_txt}]"
        )
        from src.schemas import SearchResult, ScenePayload

        candidates.append(SearchResult(payload=ScenePayload(**p), full_context_text=full_context_for_rerank))

    final_docs = pipeline.reranker.rerank(query=query, docs=candidates, top_k=settings.rag["top_k_final"])
    trace["top_docs"] = final_docs

    events = set()
    chapters = set()
    scenes = []

    for doc in final_docs:
        p = doc.payload
        scenes.append(f"- [{p.chapter_id}í™” {p.scene_idx}ì»·] {p.text}")

        c_full = pipeline.lookup.get(f"chapter_{p.chapter_id}", "")
        if c_full:
            chapters.add(f"- [Ch.{p.chapter_id}] {c_full}")
        if p.event_id:
            e_full = pipeline.lookup.get(f"event_{p.event_id}", "")
            if e_full:
                events.add(f"- [Event] {e_full}")

    final_prompt = RAG_GENERATION_SCENE.format(
        character_info=pipeline.raw_character_info,
        global_summary=pipeline.lookup.get("global", ""),
        context_summaries="\n".join(events) + "\n" + "\n".join(chapters),
        scene_details="\n".join(scenes),
        user_query=query,
    )
    trace["final_answer"] = pipeline.llm.ask(RAG_SYSTEM_SCENE, final_prompt)
    return trace


def main():
    st.markdown('<h1 style="font-size: 3rem; margin-bottom: 0.5rem;"><span style="color: #00dc64;">ToonPT</span> íŒŒì´í”„ë¼ì¸ ì‹œê°í™”</h1>', unsafe_allow_html=True)    
    st.caption("Input â†’ Router â†’ Rewriter â†’ Reranking(Top 5) â†’ Final Answer")

    with st.sidebar:
        st.subheader("ì„¤ì •")
        st.code(
            f"data_dir: {settings.paths['data_dir']}\n"
            f"qdrant_storage: {settings.paths['qdrant_storage']}\n"
            f"collection: {settings.rag['collection_name']}\n"
            f"top_k_retrieve: {settings.rag['top_k_retrieve']}\n"
            f"top_k_final: {settings.rag['top_k_final']}",
            language="javascript",
        )
        window_size = st.slider("Window size (ì•ë’¤ ë¬¸ë§¥ í™•ì¥)", 0, 3, 0, 1)
        st.divider()
        st.info("ë¼ìš°íŒ…/ë¦¬ë¼ì´íŠ¸/ë¦¬ë­í‚¹ì€ ì‹¤ì œ íŒŒì´í”„ë¼ì¸ ì»´í¬ë„ŒíŠ¸ë¥¼ ê·¸ëŒ€ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤.")

    pipeline = get_pipeline()

    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ê¸°ì¡´ ëŒ€í™” ë Œë”
    for m in st.session_state.messages:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    user_query = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
    if not user_query:
        return

    st.session_state.messages.append({"role": "user", "content": user_query})
    with st.chat_message("user"):
        st.markdown(user_query)

    # ì‹¤í–‰
    with st.chat_message("assistant"):
        with st.spinner("íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘â€¦"):
            trace = run_pipeline_with_traces(pipeline, user_query, window_size=window_size)

        # --- Router ---
        st.subheader("Router")
        intent = trace.get("intent")
        cid = trace.get("chapter_id")
        if intent == "lookup_chapter":
            st.info(f"Intent: **{intent}** Â· Chapter: **{cid}**")
        else:
            st.info(f"Intent: **{intent}**")

        # --- Rewriter ---
        st.subheader("Rewriter")
        if trace.get("rewritten_query"):
            st.code(trace["rewritten_query"], language="text")
        else:
            st.caption("lookup ëª¨ë“œì—ì„œëŠ” Rewriter ë‹¨ê³„ê°€ ìƒëµë©ë‹ˆë‹¤.")

        # --- Reranking Similarity Score Visualization ---
        top_docs = trace.get("top_docs") or []
        if top_docs:
            st.subheader("Reranking Similarity Score (Top 5)")
            # Top 5 similarity ìŠ¤ì½”ì–´ë¥¼ ê·¸ë˜í”„ë¡œ ì‹œê°í™”
            scores_data = {}
            for i, doc in enumerate(top_docs[:5], 1):
                p = doc.payload
                label = f"{p.chapter_id}í™”-{p.scene_idx}ì»·"
                scores_data[label] = float(doc.score)
            
            # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê·¸ë˜í”„ ìƒì„±
            df_scores = pd.DataFrame({
                'Document': list(scores_data.keys()),
                'Similarity Score': list(scores_data.values())
            })
            
            if PLOTLY_AVAILABLE:
                # Plotlyë¡œ êº¾ì€ì„  ê·¸ë˜í”„ ìƒì„± (ë‹¤í¬ ë°°ê²½ + ì£¼í™©ìƒ‰ ì„ )
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=df_scores['Document'],
                    y=df_scores['Similarity Score'],
                    mode='lines+markers',
                    name='Similarity Score',
                    line=dict(color='#00dc64', width=3),
                    marker=dict(color='#00dc64', size=8)
                ))
                
                # ë‹¤í¬ ë°°ê²½ ì„¤ì •
                fig.update_layout(
                    height=300,
                    plot_bgcolor='#0e1117',
                    paper_bgcolor='#0e1117',
                    font=dict(color='#e6e6e6'),
                    xaxis=dict(
                        gridcolor='rgba(255,255,255,0.1)',
                        title=dict(text='Document', font=dict(color='#e6e6e6'))
                    ),
                    yaxis=dict(
                        gridcolor='rgba(255,255,255,0.1)',
                        title=dict(text='Similarity Score', font=dict(color='#e6e6e6'))
                    ),
                    margin=dict(l=50, r=20, t=20, b=50)
                )
                
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("âš ï¸ plotlyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê·¸ë˜í”„ë¥¼ í‘œì‹œí•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: `pip install plotly`")
                # ëŒ€ì²´ë¡œ ê¸°ë³¸ ì°¨íŠ¸ ì‚¬ìš©
                df_scores_indexed = df_scores.set_index('Document')
                st.line_chart(df_scores_indexed, height=300)
            
            st.caption(f"Top 5 ë¬¸ì„œì˜ Reranker Similarity Score ë¶„í¬")

        # --- Reranking (Top 5) ---
        st.subheader("Reranking (Top 5)")
        if not top_docs:
            st.caption("lookup ëª¨ë“œ ë˜ëŠ” ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒìœ¼ë¡œ ì¸í•´ Top 5 ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            webtoon_title = _get_webtoon_title()
            cols = st.columns(5, gap="small")
            for i, doc in enumerate(top_docs[:5]):
                p = doc.payload
                score = float(doc.score)
                title = webtoon_title
                subtitle = f"{p.chapter_id}í™” Â· ì”¬ {p.scene_idx}"
                img_path = _resolve_image_path(p.image_file)

                with cols[i]:
                    st.markdown('<div class="rag-card">', unsafe_allow_html=True)
                    st.markdown(f'<div class="rag-title">{title}</div>', unsafe_allow_html=True)
                    st.markdown(
                        f'<div class="rag-meta">{subtitle}<br/>Similarity: <b>{score:.4f}</b></div>',
                        unsafe_allow_html=True,
                    )
                    if img_path:
                        st.image(img_path, use_container_width=True)
                        st.markdown(f'<p style="color: #00dc64; font-size: 0.85rem; margin-top: 0.25rem;">{p.image_file}</p>', unsafe_allow_html=True)
                    else:
                        # ë””ë²„ê¹…: ì–´ë–¤ image_file ê°’ì´ ë“¤ì–´ì™”ëŠ”ì§€ í™•ì¸
                        debug_info = f"image_file: `{p.image_file}` | data_dir: `{settings.paths['data_dir']}`"
                        st.markdown(f'<p style="color: #00dc64; font-size: 0.85rem;">ì¸ë„¤ì¼ì„ ì°¾ì§€ ëª»í•¨: `{p.image_file}`</p>', unsafe_allow_html=True)
                        st.caption(f"ë””ë²„ê·¸: {debug_info}")
                    st.caption(p.text[:120] + ("â€¦" if len(p.text) > 120 else ""))
                    st.markdown("</div>", unsafe_allow_html=True)
                    
        # --- Final Answer ---
        st.subheader("Final Answer")
        answer = trace.get("final_answer", "")
        
        # ë‹µë³€ í‘œì‹œ (white ìƒ‰ìƒ ì ìš©)
        if answer:
            answer_container = st.empty()
            full_text = ""
            for chunk in _stream_text(answer):
                full_text += chunk
                answer_container.markdown(f'<div class="final-answer-text">{full_text}</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="final-answer-text">ë‹µë³€ ìƒì„± ì‹¤íŒ¨</div>', unsafe_allow_html=True)

    # ì„¸ì…˜ì— ë‹µë³€ ì €ì¥ (í•œ ë²ˆë§Œ)
    st.session_state.messages.append({"role": "assistant", "content": trace.get("final_answer", "")})


if __name__ == "__main__":
    main()