import os
import sys
from pathlib import Path
from typing import Optional, Tuple, List, Iterable

# í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸ ë° ì—ëŸ¬ í•¸ë“¤ë§
MISSING_PACKAGES = []

try:
    import streamlit as st
except ImportError:
    MISSING_PACKAGES.append("streamlit")

try:
    from qdrant_client import QdrantClient
except ImportError:
    MISSING_PACKAGES.append("qdrant-client")

try:
    from sentence_transformers import SentenceTransformer
except ImportError:
    MISSING_PACKAGES.append("sentence-transformers")

try:
    import torch
except ImportError:
    MISSING_PACKAGES.append("torch")

if MISSING_PACKAGES:
    print("=" * 60)
    print("âŒ í•„ìˆ˜ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    print("=" * 60)
    print(f"ëˆ„ë½ëœ íŒ¨í‚¤ì§€: {', '.join(MISSING_PACKAGES)}")
    print("\nì„¤ì¹˜ ë°©ë²•:")
    print(f"  {sys.executable} -m pip install {' '.join(MISSING_PACKAGES)}")
    print("\në˜ëŠ” ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰:")
    print("  python install_dependencies.py")
    print("=" * 60)
    sys.exit(1)

import streamlit as st

# src ëª¨ë“ˆ ì„í¬íŠ¸ (ì—ëŸ¬ í•¸ë“¤ë§)
try:
    from src import WebtoonDB, EmbeddingEngine, ExaoneLLM, RAGPipeline
    from src.config import settings
    from src.prompts import (
        RAG_GENERATION_CHAPTER,
        RAG_GENERATION_SCENE,
        RAG_SYSTEM_CHAPTER,
        RAG_SYSTEM_SCENE,
    )
except ImportError as e:
    st.error(f"âŒ ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    st.info(
        f"""
        **í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤:**
        
        í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:
        ```bash
        {sys.executable} -m pip install qdrant-client sentence-transformers transformers torch PyYAML rank-bm25 kiwipiepy
        ```
        
        ë˜ëŠ” ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰:
        ```bash
        python install_dependencies.py
        ```
        """
    )
    st.stop()


st.set_page_config(
    page_title="Webtoon RAG Pipeline Viewer",
    page_icon="ğŸ•¸ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)


_DARK_CSS = """

<style>
  header[data-testid="stHeader"] {
    display: none;
  }
  .stApp { background: #0e1117; color: #e6e6e6; }
  .block-container { padding-top: 1.25rem; }
  /* Chat-like cards */
  .rag-card {
    background: rgba(255,255,255,0.04);
    border: 1px solid rgba(255,255,255,0.08);
    border-radius: 14px;
    padding: 14px 14px 10px 14px;
  }
  .rag-title {
    font-weight: 700;
    font-size: 0.95rem;
    margin-bottom: 0.25rem;
  }
  .rag-meta {
    opacity: 0.85;
    font-size: 0.85rem;
    margin-bottom: 0.5rem;
  }
  /* Make sidebar fit dark mode better */
  section[data-testid="stSidebar"] {
    background: #0b0f14;
    border-right: 1px solid rgba(255,255,255,0.06);
  }
</style>
"""
st.markdown(_DARK_CSS, unsafe_allow_html=True)


@st.cache_resource(show_spinner="ëª¨ë¸/DB ì´ˆê¸°í™” ì¤‘â€¦ (ìµœì´ˆ 1íšŒë§Œ ì˜¤ë˜ ê±¸ë ¤ìš”)")
def get_pipeline() -> RAGPipeline:
    """
    config/config.yaml(settings)ì„ ì°¸ì¡°í•˜ì—¬ ì»´í¬ë„ŒíŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ê³ ,
    Streamlit ì¬ì‹¤í–‰ ì‹œì—ë„ ë¦¬ì†ŒìŠ¤ë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    db = WebtoonDB()
    embedder = EmbeddingEngine()
    llm = ExaoneLLM()
    return RAGPipeline(db, embedder, llm)


def _resolve_image_path(image_file: str) -> Optional[str]:
    """
    ê²€ìƒ‰ ê²°ê³¼ payloadì˜ image_fileì„ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ í•´ì„í•©ë‹ˆë‹¤.
    - ì ˆëŒ€ê²½ë¡œë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    - ìƒëŒ€ê²½ë¡œë©´ settings.paths['data_dir'] ê¸°ì¤€ìœ¼ë¡œ ì—¬ëŸ¬ í›„ë³´ë¥¼ íƒìƒ‰
    """
    if not image_file:
        return None

    p = Path(image_file)
    if p.is_absolute() and p.exists():
        return str(p)

    data_dir = Path(settings.paths["data_dir"])

    candidates: List[Path] = []
    # í”í•œ êµ¬ì¡° í›„ë³´ë“¤
    candidates.append(data_dir / image_file)
    candidates.append(data_dir / "images" / image_file)
    candidates.append(data_dir / "imgs" / image_file)
    candidates.append(data_dir / "thumbnails" / image_file)
    candidates.append(data_dir / "scenes" / image_file)

    # í™•ì¥ìê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„
    if p.suffix == "":
        for ext in [".png", ".jpg", ".jpeg", ".webp"]:
            candidates.append(data_dir / f"{image_file}{ext}")
            candidates.append(data_dir / "images" / f"{image_file}{ext}")
            candidates.append(data_dir / "thumbnails" / f"{image_file}{ext}")

    for c in candidates:
        if c.exists():
            return str(c)

    return None


def _stream_text(text: str, chunk: int = 40) -> Iterable[str]:
    """LLMì´ ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë‹ˆ, UIì—ì„œë§Œ í…ìŠ¤íŠ¸ë¥¼ ë‚˜ëˆ ì„œ í˜ë ¤ë³´ëƒ…ë‹ˆë‹¤."""
    if not text:
        return
    for i in range(0, len(text), chunk):
        yield text[i : i + chunk]


def _get_webtoon_title() -> str:
    """
    ë°ì´í„°ì…‹ì´ ë‹¨ì¼ ì›¹íˆ°ì¸ ê²½ìš°ê°€ ë§ì•„ ê¸°ë³¸ íƒ€ì´í‹€ì„ ì œê³µ.
    ë°ì´í„° í´ë”ì— metadata/global_summary ë“±ì´ ìˆìœ¼ë©´ ê±°ê¸°ì„œë„ ì‹œë„í•©ë‹ˆë‹¤(ì—†ìœ¼ë©´ ê¸°ë³¸ê°’).
    """
    data_dir = Path(settings.paths["data_dir"])
    for candidate in [data_dir / "metadata.json", data_dir / "meta.json", data_dir / "global_summary.json"]:
        try:
            if candidate.exists():
                import json

                obj = json.loads(candidate.read_text(encoding="utf-8"))
                for key in ["title", "webtoon_title", "name"]:
                    v = obj.get(key)
                    if isinstance(v, str) and v.strip():
                        return v.strip()
        except Exception:
            pass
    return "Webtoon"


def run_pipeline_with_traces(pipeline: RAGPipeline, query: str, window_size: int = 0) -> dict:
    """
    src/pipeline.pyì˜ run() íë¦„ì„ ê·¸ëŒ€ë¡œ ë”°ë¼ê°€ë˜,
    UIì—ì„œ ë³´ì—¬ì¤„ ì¤‘ê°„ ê²°ê³¼(ì˜ë„/ì¬ì‘ì„±/Top5 ë¬¸ì„œ)ë¥¼ ê°™ì´ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    intent, cid = pipeline.router.route(query)

    trace = {
        "query": query,
        "intent": intent,
        "chapter_id": cid,
        "rewritten_query": None,
        "top_docs": [],
        "final_answer": "",
        "mode": "search",
    }

    # Case A: ì±•í„° ìš”ì•½(lookup)
    if intent == "lookup_chapter" and cid:
        trace["mode"] = "lookup_chapter"

        chapter_summary = pipeline.lookup.get(f"chapter_{cid}", "ì •ë³´ ì—†ìŒ")
        event_id = pipeline.chapter_event_map.get(cid)
        event_summary = pipeline.lookup.get(f"event_{event_id}", "") if event_id else ""

        full_context = ""
        if event_summary:
            full_context += f"[Related Event Summary (Event {event_id})]\n{event_summary}\n\n"
        full_context += f"[Target Chapter Summary (Chapter {cid})]\n{chapter_summary}"

        formatted_prompt = RAG_GENERATION_CHAPTER.format(
            user_query=query,
            character_info=pipeline.raw_character_info,
            global_summary=pipeline.lookup.get("global", ""),
            context_summaries=full_context,
        )
        trace["final_answer"] = pipeline.llm.ask(RAG_SYSTEM_CHAPTER, formatted_prompt)
        return trace

    # Case B: ì¼ë°˜ ê²€ìƒ‰(search)
    rewritten = pipeline.expander.expand(query)
    trace["rewritten_query"] = rewritten

    scanned_points = pipeline.hybrid_search(query, rewritten, top_k=settings.rag["top_k_retrieve"])
    if not scanned_points:
        trace["final_answer"] = "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        return trace

    window_texts = pipeline._fetch_window_context(scanned_points, window_size=window_size)

    candidates = []
    for hit in scanned_points:
        p = hit.payload
        center_id = hit.id

        extended_text = window_texts.get(center_id, p["text"])
        c_txt = pipeline.lookup.get(f"chapter_{p['chapter_id']}", "")
        e_txt = pipeline.lookup.get(f"event_{p.get('event_id')}", "")

        full_context_for_rerank = (
            f"{extended_text}\n\n"
            f"[ì°¸ê³  - ì‚¬ê±´: {e_txt}]\n"
            f"[ì°¸ê³  - ì „ì²´: {c_txt}]"
        )
        from src.schemas import SearchResult, ScenePayload

        candidates.append(SearchResult(payload=ScenePayload(**p), full_context_text=full_context_for_rerank))

    final_docs = pipeline.reranker.rerank(query=query, docs=candidates, top_k=settings.rag["top_k_final"])
    trace["top_docs"] = final_docs

    events = set()
    chapters = set()
    scenes = []

    for doc in final_docs:
        p = doc.payload
        scenes.append(f"- [{p.chapter_id}í™” {p.scene_idx}ì»·] {p.text}")

        c_full = pipeline.lookup.get(f"chapter_{p.chapter_id}", "")
        if c_full:
            chapters.add(f"- [Ch.{p.chapter_id}] {c_full}")
        if p.event_id:
            e_full = pipeline.lookup.get(f"event_{p.event_id}", "")
            if e_full:
                events.add(f"- [Event] {e_full}")

    final_prompt = RAG_GENERATION_SCENE.format(
        character_info=pipeline.raw_character_info,
        global_summary=pipeline.lookup.get("global", ""),
        context_summaries="\n".join(events) + "\n" + "\n".join(chapters),
        scene_details="\n".join(scenes),
        user_query=query,
    )
    trace["final_answer"] = pipeline.llm.ask(RAG_SYSTEM_SCENE, final_prompt)
    return trace


def main():
    st.title("RAG íŒŒì´í”„ë¼ì¸ ì‹œê°í™”")
    st.caption("Input â†’ Router â†’ Rewriter â†’ Reranking(Top 5) â†’ Final Answer")

    with st.sidebar:
        st.subheader("ì„¤ì •")
        st.write("`config/config.yaml` ê¸°ì¤€ìœ¼ë¡œ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.")
        st.code(
            f"data_dir: {settings.paths['data_dir']}\n"
            f"qdrant_storage: {settings.paths['qdrant_storage']}\n"
            f"collection: {settings.rag['collection_name']}\n"
            f"top_k_retrieve: {settings.rag['top_k_retrieve']}\n"
            f"top_k_final: {settings.rag['top_k_final']}",
            language="yaml",
        )
        window_size = st.slider("Window size (ì•ë’¤ ë¬¸ë§¥ í™•ì¥)", 0, 3, 0, 1)
        st.divider()
        st.info("ë¼ìš°íŒ…/ë¦¬ë¼ì´íŠ¸/ë¦¬ë­í‚¹ì€ ì‹¤ì œ íŒŒì´í”„ë¼ì¸ ì»´í¬ë„ŒíŠ¸ë¥¼ ê·¸ëŒ€ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤.")

    pipeline = get_pipeline()

    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ê¸°ì¡´ ëŒ€í™” ë Œë”
    for m in st.session_state.messages:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    user_query = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
    if not user_query:
        return

    st.session_state.messages.append({"role": "user", "content": user_query})
    with st.chat_message("user"):
        st.markdown(user_query)

    # ì‹¤í–‰
    with st.chat_message("assistant"):
        with st.spinner("íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘â€¦"):
            trace = run_pipeline_with_traces(pipeline, user_query, window_size=window_size)

        # --- Router ---
        st.subheader("Router")
        intent = trace.get("intent")
        cid = trace.get("chapter_id")
        if intent == "lookup_chapter":
            st.info(f"Intent: **{intent}** Â· Chapter: **{cid}**")
        else:
            st.info(f"Intent: **{intent}**")

        # --- Rewriter ---
        st.subheader("Rewriter")
        if trace.get("rewritten_query"):
            st.code(trace["rewritten_query"], language="text")
        else:
            st.caption("lookup ëª¨ë“œì—ì„œëŠ” Rewriter ë‹¨ê³„ê°€ ìƒëµë©ë‹ˆë‹¤.")

        # --- Reranking (Top 5) ---
        st.subheader("Reranking (Top 5)")
        top_docs = trace.get("top_docs") or []
        if not top_docs:
            st.caption("lookup ëª¨ë“œ ë˜ëŠ” ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒìœ¼ë¡œ ì¸í•´ Top 5 ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            webtoon_title = _get_webtoon_title()
            cols = st.columns(5, gap="small")
            for i, doc in enumerate(top_docs[:5]):
                p = doc.payload
                score = float(doc.score)
                title = webtoon_title
                subtitle = f"{p.chapter_id}í™” Â· ì”¬ {p.scene_idx}"
                img_path = _resolve_image_path(p.image_file)

                with cols[i]:
                    st.markdown('<div class="rag-card">', unsafe_allow_html=True)
                    st.markdown(f'<div class="rag-title">{title}</div>', unsafe_allow_html=True)
                    st.markdown(
                        f'<div class="rag-meta">{subtitle}<br/>Similarity: <b>{score:.4f}</b></div>',
                        unsafe_allow_html=True,
                    )
                    if img_path:
                        st.image(img_path, use_container_width=True)
                    else:
                        st.caption(f"ì¸ë„¤ì¼ì„ ì°¾ì§€ ëª»í•¨: `{p.image_file}`")
                    st.caption(p.text[:120] + ("â€¦" if len(p.text) > 120 else ""))
                    st.markdown("</div>", unsafe_allow_html=True)

        # --- Final Answer ---
        st.subheader("Final Answer")
        answer = trace.get("final_answer", "")
        st.write_stream(_stream_text(answer)) if answer else st.write("ë‹µë³€ ìƒì„± ì‹¤íŒ¨")

    st.session_state.messages.append({"role": "assistant", "content": trace.get("final_answer", "")})


if __name__ == "__main__":
    # Streamlit ì‹¤í–‰ ì‹œì—ëŠ” ì´ ë¸”ë¡ì´ ì‹¤í–‰ë˜ì§€ ì•Šì§€ë§Œ,
    # python app.py í˜•íƒœë¡œ ì‹¤í–‰í•˜ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•©ë‹ˆë‹¤.
    main()

